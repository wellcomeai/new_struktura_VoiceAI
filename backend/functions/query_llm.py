# backend/functions/query_llm.py
"""
–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ ChatGPT API —á–µ—Ä–µ–∑ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞.
–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –∫–∞–∫ –∫–ª–∞—Å—Å FunctionBase –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –≤ —Å–∏—Å—Ç–µ–º–µ.
"""

import openai
import asyncio
from typing import Dict, Any

from backend.core.config import settings
from backend.core.logging import get_logger
from backend.functions.base import FunctionBase
from backend.functions.registry import register_function

logger = get_logger(__name__)


@register_function
class QueryLLMFunction(FunctionBase):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–π LLM –º–æ–¥–µ–ª–∏"""
    
    @classmethod
    def get_name(cls) -> str:
        return "query_llm"
    
    @classmethod
    def get_display_name(cls) -> str:
        return "–ó–∞–ø—Ä–æ—Å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–π LLM (ChatGPT)"
    
    @classmethod
    def get_description(cls) -> str:
        return "–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–π LLM –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"
    
    @classmethod
    def get_parameters(cls) -> Dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ –∑–∞–¥–∞—á–∏ –¥–ª—è LLM –º–æ–¥–µ–ª–∏"
                },
                "model": {
                    "type": "string", 
                    "description": "–ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (gpt-4, gpt-3.5-turbo)",
                    "default": "gpt-4o-mini"
                }
            },
            "required": ["prompt"]
        }
    
    @classmethod
    def get_example_prompt(cls) -> str:
        return """
<p>–¢—ã –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é <code>query_llm</code> –¥–ª—è –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ ChatGPT.</p>

<p><strong>–ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ?</strong></p>
<p>–ì–æ–ª–æ—Å–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ä–µ–ø–ª–∏–∫. –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ –∫–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–∫—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å.</p>

<p><strong>–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</strong></p>
<ul>
    <li>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –Ω–∞–ø–∏—Å–∞—Ç—å <strong>–¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç</strong> (—Å—Ç–∞—Ç—å—é, –ø–∏—Å—å–º–æ, –æ—Ç—á–µ—Ç, –∫–æ–¥)</li>
    <li>–ù—É–∂–µ–Ω <strong>–¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑</strong> –∏–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ</li>
    <li>–¢—Ä–µ–±—É–µ—Ç—Å—è <strong>—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç</strong> —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –¥–µ—Ç–∞–ª–µ–π</li>
    <li>–ó–∞–¥–∞—á–∞ —Ç—Ä–µ–±—É–µ—Ç <strong>–≥–ª—É–±–æ–∫–æ–≥–æ reasoning</strong> –∏–ª–∏ –ø–æ—à–∞–≥–æ–≤–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è</li>
    <li>–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–¥–∞, —Å–∫—Ä–∏–ø—Ç–æ–≤, SQL –∑–∞–ø—Ä–æ—Å–æ–≤</li>
    <li>–ù–∞–ø–∏—Å–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π, —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤</li>
</ul>

<p><strong>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ—É–Ω–∫—Ü–∏–∏:</strong></p>
<ul>
    <li><code>prompt</code> ‚Äî –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –¥–ª—è ChatGPT</li>
    <li><code>model</code> ‚Äî –º–æ–¥–µ–ª—å: "gpt-4o-mini" (–±—ã—Å—Ç—Ä–∞—è), "gpt-4" (—É–º–Ω–∞—è), "gpt-3.5-turbo" (—ç–∫–æ–Ω–æ–º–Ω–∞—è)</li>
</ul>

<p><strong>–ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞:</strong></p>
<pre>{
  "prompt": "–ù–∞–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç—å—é –æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞—Ö –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –≤ –º–µ–¥–∏—Ü–∏–Ω–µ. –í–∫–ª—é—á–∏ –ø—Ä–∏–º–µ—Ä—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è.",
  "model": "gpt-4o-mini"
}</pre>

<p><strong>–†–µ–∑—É–ª—å—Ç–∞—Ç:</strong></p>
<pre>{
  "result": "–ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω! –†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç –≤—ã–≤–µ–¥–µ–Ω –Ω–∞ —ç–∫—Ä–∞–Ω.",
  "status": "success",
  "model_used": "gpt-4o-mini",
  "response_length": 2847,
  "full_response": "... –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ ..."
}</pre>

<p><strong>üí° –ö–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º:</strong></p>
<ul>
    <li><strong>–ì–æ–ª–æ—Å–æ–º:</strong> –æ–∑–≤—É—á—å –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)</li>
    <li><strong>–ù–∞ —ç–∫—Ä–∞–Ω–µ:</strong> –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—Å—è –≤ UI</li>
    <li><strong>–î–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:</strong> "–Ø –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç, –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –µ–≥–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ —Å–ª–µ–≤–∞"</li>
</ul>

<p><strong>‚ö†Ô∏è –í–∞–∂–Ω–æ:</strong> –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é —Ç–æ–ª—å–∫–æ –¥–ª—è –∑–∞–¥–∞—á, –≥–¥–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω—É–∂–µ–Ω –¥–ª–∏–Ω–Ω—ã–π/—Å–ª–æ–∂–Ω—ã–π –æ—Ç–≤–µ—Ç. –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –æ—Ç–≤–µ—á–∞–π –Ω–∞–ø—Ä—è–º—É—é.</p>

<p><strong>‚öôÔ∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:</strong></p>
<ul>
    <li>OpenAI API –∫–ª—é—á (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π)</li>
    <li>–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –∞–∫–∫–∞—É–Ω—Ç–µ</li>
</ul>
"""
    
    @staticmethod
    async def execute(arguments: Dict[str, Any], context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ ChatGPT API –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        
        Args:
            arguments: –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Ñ—É–Ω–∫—Ü–∏–∏ (prompt, model)
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å websocket –∏ –¥—Ä—É–≥–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        """
        try:
            prompt = arguments.get("prompt")
            model = arguments.get("model", "gpt-4o-mini")
            
            if not prompt:
                error_msg = "Prompt is required"
                logger.error(f"[QUERY_LLM] {error_msg}")
                return {"error": error_msg, "status": "error"}
            
            logger.info(f"[QUERY_LLM] Executing query: {prompt[:100]}...")
            
            # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            api_key = None
            
            if context and "assistant_config" in context:
                assistant_config = context["assistant_config"]
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                if hasattr(assistant_config, "user_id") and assistant_config.user_id:
                    from backend.models.user import User
                    db_session = context.get("db_session")
                    
                    if db_session:
                        try:
                            user = db_session.query(User).get(assistant_config.user_id)
                            if user and user.openai_api_key:
                                api_key = user.openai_api_key
                                logger.info(f"[QUERY_LLM] Using user's OpenAI API key")
                            else:
                                api_key = settings.OPENAI_API_KEY
                                logger.info(f"[QUERY_LLM] Using system OpenAI API key")
                        except Exception as e:
                            logger.error(f"[QUERY_LLM] Error getting user API key: {e}")
                            api_key = settings.OPENAI_API_KEY
                    else:
                        api_key = settings.OPENAI_API_KEY
                else:
                    api_key = settings.OPENAI_API_KEY
            else:
                api_key = settings.OPENAI_API_KEY
            
            if not api_key:
                error_msg = "OpenAI API key not found"
                logger.error(f"[QUERY_LLM] {error_msg}")
                return {"error": error_msg, "status": "error"}
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
            client = openai.AsyncOpenAI(api_key=api_key)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ ChatGPT
            messages = [
                {
                    "role": "system", 
                    "content": "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –ø–æ–¥—Ä–æ–±–Ω–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ. –ò—Å–ø–æ–ª—å–∑—É–π markdown –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ]
            
            logger.info(f"[QUERY_LLM] Sending request to {model}...")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = await client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=2000,
                temperature=0.7
            )
            
            llm_result = response.choices[0].message.content
            
            logger.info(f"[QUERY_LLM] LLM response received: {len(llm_result)} characters")
            logger.info(f"[QUERY_LLM] Preparing result for handler (no direct WebSocket send)")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ handler_realtime_new.py
            # WebSocket –æ—Ç–ø—Ä–∞–≤–∫—É –¥–µ–ª–∞–µ—Ç handler, –∞ –Ω–µ —Ñ—É–Ω–∫—Ü–∏—è (–∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è)
            return {
                "result": f"–ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω! –†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç –≤—ã–≤–µ–¥–µ–Ω –Ω–∞ —ç–∫—Ä–∞–Ω —Å–ª–µ–≤–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(llm_result)} —Å–∏–º–≤–æ–ª–æ–≤.",
                "status": "success",
                "model_used": model,
                "response_length": len(llm_result),
                "full_response": llm_result  # handler_realtime_new.py –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —ç—Ç–æ –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥
            }
            
        except Exception as e:
            error_msg = f"Error executing LLM query: {str(e)}"
            logger.error(f"[QUERY_LLM] {error_msg}")
            return {
                "error": error_msg,
                "status": "error"
            }
