"""
üß™ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–ô OpenAI Realtime API Client —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- Sentence boundary detection –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π latency
- Chunked TTS streaming
- Aggressive interruption handling
- Parallel processing LLM ‚Üí TTS
"""

import asyncio
import websockets
import json
import base64
import logging
from typing import Optional, Callable, Dict, Any
from .sentence_detector import StreamingSentenceDetector

logger = logging.getLogger(__name__)


class OpenAIRealtimeClientStreaming:
    """
    –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI Realtime API (GA) —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
    """
    
    def __init__(
        self,
        api_key: str,
        model: str = "gpt-4o-realtime-preview-2024-12-17",
        voice: str = "alloy",
        language: str = "ru",
        instructions: Optional[str] = None,
        temperature: float = 0.8,
        max_tokens: int = 300  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ä–µ–ø–ª–∏–∫
    ):
        self.api_key = api_key
        self.model = model
        self.voice = voice
        self.language = language
        self.instructions = instructions or "–¢—ã –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Ñ—Ä–∞–∑–∞–º–∏."
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        self.ws: Optional[websockets.WebSocketClientProtocol] = None
        self.session_id: Optional[str] = None
        
        # Sentence detector –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è
        self.sentence_detector = StreamingSentenceDetector(
            language=language,
            min_chunk_length=30  # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞
        )
        
        # –ö–æ–ª–±—ç–∫–∏
        self.on_audio_delta: Optional[Callable] = None
        self.on_text_delta: Optional[Callable] = None
        self.on_sentence_ready: Optional[Callable] = None  # üÜï –¥–ª—è TTS chunking
        self.on_error: Optional[Callable] = None
        self.on_interruption: Optional[Callable] = None
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.is_speaking = False
        self.current_response_id: Optional[str] = None
        self.text_buffer = ""
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.stats = {
            "first_token_latency": None,
            "first_audio_latency": None,
            "sentences_sent": 0,
            "interruptions": 0
        }
    
    async def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenAI Realtime API"""
        url = f"wss://api.openai.com/v1/realtime?model={self.model}"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "OpenAI-Beta": "realtime=v1"
        }
        
        try:
            self.ws = await websockets.connect(url, extra_headers=headers)
            logger.info(f"‚úÖ Connected to OpenAI Realtime API (streaming mode)")
            
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
            await self._configure_session()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–æ–æ–±—â–µ–Ω–∏–π
            asyncio.create_task(self._receive_messages())
            
        except Exception as e:
            logger.error(f"‚ùå Connection error: {e}")
            if self.on_error:
                await self.on_error(str(e))
            raise
    
    async def _configure_session(self):
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è streaming"""
        config = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": self.instructions,
                "voice": self.voice,
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "input_audio_transcription": {
                    "model": "whisper-1"
                },
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": 0.5,
                    "prefix_padding_ms": 300,
                    "silence_duration_ms": 500  # –ë—ã—Å—Ç—Ä–æ–µ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—É–∑—ã
                },
                "temperature": self.temperature,
                "max_response_output_tokens": self.max_tokens  # –ö–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã
            }
        }
        
        await self.ws.send(json.dumps(config))
        logger.info("üìù Session configured for streaming optimization")
    
    async def send_audio_chunk(self, audio_data: bytes):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ —á–∞–Ω–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if not self.ws:
            return
        
        base64_audio = base64.b64encode(audio_data).decode('utf-8')
        
        message = {
            "type": "input_audio_buffer.append",
            "audio": base64_audio
        }
        
        await self.ws.send(json.dumps(message))
    
    async def commit_audio_buffer(self):
        """–ö–æ–º–º–∏—Ç –∞—É–¥–∏–æ –±—É—Ñ–µ—Ä–∞ - –Ω–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if not self.ws:
            return
        
        message = {"type": "input_audio_buffer.commit"}
        await self.ws.send(json.dumps(message))
        
        # –°–æ–∑–¥–∞–µ–º response –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
        await self.create_response()
    
    async def create_response(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ response –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"""
        if not self.ws:
            return
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º sentence detector
        self.sentence_detector.buffer = ""
        self.text_buffer = ""
        
        message = {
            "type": "response.create",
            "response": {
                "modalities": ["text", "audio"],
                "instructions": "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –æ–¥–Ω–∏–º-–¥–≤—É–º—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏."
            }
        }
        
        await self.ws.send(json.dumps(message))
        logger.info("üé§ Response creation triggered")
    
    async def cancel_response(self):
        """–û—Ç–º–µ–Ω–∞ —Ç–µ–∫—É—â–µ–≥–æ response (–¥–ª—è interruption)"""
        if not self.ws or not self.current_response_id:
            return
        
        message = {
            "type": "response.cancel"
        }
        
        await self.ws.send(json.dumps(message))
        
        self.stats["interruptions"] += 1
        self.is_speaking = False
        self.current_response_id = None
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –±—É—Ñ–µ—Ä—ã
        self.sentence_detector.buffer = ""
        self.text_buffer = ""
        
        logger.info(f"üõë Response cancelled (interruption #{self.stats['interruptions']})")
        
        if self.on_interruption:
            await self.on_interruption()
    
    async def _receive_messages(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç OpenAI"""
        try:
            async for message in self.ws:
                data = json.loads(message)
                await self._handle_message(data)
                
        except websockets.exceptions.ConnectionClosed:
            logger.warning("‚ö†Ô∏è WebSocket connection closed")
        except Exception as e:
            logger.error(f"‚ùå Error in receive loop: {e}")
            if self.on_error:
                await self.on_error(str(e))
    
    async def _handle_message(self, data: Dict[str, Any]):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç OpenAI"""
        msg_type = data.get("type")
        
        # === SESSION EVENTS ===
        if msg_type == "session.created":
            self.session_id = data.get("session", {}).get("id")
            logger.info(f"‚úÖ Session created: {self.session_id}")
        
        elif msg_type == "session.updated":
            logger.info("‚úÖ Session updated")
        
        # === RESPONSE EVENTS ===
        elif msg_type == "response.created":
            self.current_response_id = data.get("response", {}).get("id")
            self.is_speaking = True
            logger.info(f"üéØ Response started: {self.current_response_id}")
        
        elif msg_type == "response.done":
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫ –±—É—Ñ–µ—Ä–∞
            await self._flush_sentence_buffer()
            
            self.is_speaking = False
            self.current_response_id = None
            logger.info(f"‚úÖ Response complete. Sentences sent: {self.stats['sentences_sent']}")
        
        # === TEXT STREAMING (üî• –≥–ª–∞–≤–Ω–æ–µ –¥–ª—è sentence detection) ===
        elif msg_type == "response.text.delta":
            delta = data.get("delta", "")
            self.text_buffer += delta
            
            # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            sentences = self.sentence_detector.add_chunk(delta)
            
            for sentence in sentences:
                await self._send_sentence_to_tts(sentence)
            
            # –ö–æ–ª–±—ç–∫ –¥–ª—è UI
            if self.on_text_delta:
                await self.on_text_delta(delta)
        
        elif msg_type == "response.text.done":
            text = data.get("text", "")
            logger.info(f"üí¨ Text complete: {text[:100]}...")
        
        # === AUDIO STREAMING ===
        elif msg_type == "response.audio.delta":
            audio_b64 = data.get("delta", "")
            if audio_b64 and self.on_audio_delta:
                audio_bytes = base64.b64decode(audio_b64)
                await self.on_audio_delta(audio_bytes)
        
        elif msg_type == "response.audio.done":
            logger.info("üîä Audio streaming complete")
        
        # === INPUT AUDIO EVENTS ===
        elif msg_type == "input_audio_buffer.speech_started":
            logger.info("üéôÔ∏è User started speaking")
            # –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π –æ—Ç–≤–µ—Ç –µ—Å–ª–∏ –æ–Ω –∏–¥–µ—Ç
            if self.is_speaking:
                await self.cancel_response()
        
        elif msg_type == "input_audio_buffer.speech_stopped":
            logger.info("üéôÔ∏è User stopped speaking")
        
        elif msg_type == "input_audio_buffer.committed":
            logger.info("‚úÖ Audio buffer committed")
        
        # === CONVERSATION EVENTS ===
        elif msg_type == "conversation.item.created":
            item = data.get("item", {})
            logger.info(f"üíæ Item created: {item.get('type')}")
        
        # === ERROR HANDLING ===
        elif msg_type == "error":
            error = data.get("error", {})
            error_msg = error.get("message", "Unknown error")
            logger.error(f"‚ùå OpenAI Error: {error_msg}")
            
            if self.on_error:
                await self.on_error(error_msg)
        
        # === RATE LIMIT ===
        elif msg_type == "rate_limits.updated":
            limits = data.get("rate_limits", [])
            logger.debug(f"üìä Rate limits: {limits}")
    
    async def _send_sentence_to_tts(self, sentence: str):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –≥–æ—Ç–æ–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ TTS –∫–æ–ª–±—ç–∫"""
        if not sentence or len(sentence) < 5:
            return
        
        self.stats["sentences_sent"] += 1
        
        logger.info(f"üì§ Sentence #{self.stats['sentences_sent']}: {sentence[:50]}...")
        
        if self.on_sentence_ready:
            await self.on_sentence_ready(sentence)
    
    async def _flush_sentence_buffer(self):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Å—Ç–∞—Ç–∫–∞ –±—É—Ñ–µ—Ä–∞ –≤ –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞"""
        final_sentence = self.sentence_detector.flush()
        if final_sentence:
            await self._send_sentence_to_tts(final_sentence)
    
    async def disconnect(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        if self.ws:
            await self.ws.close()
            logger.info("üëã Disconnected from OpenAI Realtime API")
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        return {
            **self.stats,
            "buffer_size": len(self.sentence_detector.buffer),
            "is_speaking": self.is_speaking
        }
