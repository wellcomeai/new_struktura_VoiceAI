"""
Real-time WebSocket Handler with OpenAI Realtime API (GA) - v2.11
OpenAI VAD Only Architecture - Simplified

üî• NEW in v2.11 - SIMPLIFIED ARCHITECTURE:
- –£–±—Ä–∞–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–≥–æ commit (OpenAI –¥–µ–ª–∞–µ—Ç auto commit)
- –£–ø—Ä–æ—â–µ–Ω–∞ –ª–æ–≥–∏–∫–∞ –ø–µ—Ä–µ—Å—ã–ª–∫–∏ –∞—É–¥–∏–æ (—Ç–æ–ª—å–∫–æ forward chunks)
- –ö–æ–¥ –ø—Ä–æ—â–µ –Ω–∞ 15%, –º–µ–Ω—å—à–µ —Ç–æ—á–µ–∫ –æ—Ç–∫–∞–∑–∞
- OpenAI server VAD —É–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º

Compatible with:
- openai_client_new.py v3.1 (OpenAI GA + server VAD)
- widget.js v3.2.2 (OpenAI VAD Only - Simplified)
"""

import asyncio
import json
import os
import base64
from datetime import datetime
from typing import Dict, Optional, Any
from fastapi import WebSocket, WebSocketDisconnect

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–´–ï –ò–ú–ü–û–†–¢–´ –¥–ª—è –≤–∞—à–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞:
from backend.db.session import SessionLocal
from backend.models import AssistantConfig, Conversation  # ‚Üê –ü—Ä–∞–≤–∏–ª—å–Ω–æ!
from backend.websockets.openai_client_new import RealtimeClient

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π
import httpx
from bs4 import BeautifulSoup

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
active_connections: Dict[str, RealtimeClient] = {}

def log_to_render(message: str, level: str = "INFO"):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å timestamp –¥–ª—è Render"""
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    print(f"[{timestamp}] [{level}] [v2.11 OpenAI VAD] {message}", flush=True)

# ==================== ASYNC FUNCTION IMPLEMENTATIONS ====================

async def query_llm(query: str, context: Optional[str] = None) -> Dict[str, Any]:
    """
    v2.10: Async LLM query function
    –î–µ–ª–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM —á–µ—Ä–µ–∑ OpenAI –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    """
    log_to_render(f"[FUNCTION] query_llm called with query: {query[:100]}...")
    
    try:
        import openai
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º prompt —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –µ—Å–ª–∏ –µ—Å—Ç—å
        messages = []
        
        if context:
            messages.append({
                "role": "system",
                "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}"
            })
        
        messages.append({
            "role": "user",
            "content": query
        })
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI API
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY not found")
        
        client = openai.AsyncOpenAI(api_key=api_key)
        
        response = await client.chat.completions.create(
            model="gpt-4o-mini",  # –ë—ã—Å—Ç—Ä–∞—è –∏ –¥–µ—à–µ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π
            messages=messages,
            max_tokens=500,
            temperature=0.7
        )
        
        result = response.choices[0].message.content
        
        log_to_render(f"[FUNCTION] query_llm result: {result[:100]}...")
        
        return {
            "success": True,
            "result": result,
            "model": "gpt-4o-mini"
        }
        
    except Exception as e:
        log_to_render(f"[FUNCTION] query_llm error: {str(e)}", "ERROR")
        return {
            "success": False,
            "error": str(e)
        }

async def get_current_weather(location: str, unit: str = "celsius") -> Dict[str, Any]:
    """
    v2.10: Async weather function
    –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â—É—é –ø–æ–≥–æ–¥—É –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –ª–æ–∫–∞—Ü–∏–∏
    """
    log_to_render(f"[FUNCTION] get_current_weather called for {location}")
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenWeatherMap API (–Ω—É–∂–µ–Ω API –∫–ª—é—á –≤ .env)
        api_key = os.getenv("OPENWEATHER_API_KEY")
        
        if not api_key:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–ª—é—á–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            log_to_render("[FUNCTION] No OpenWeatherMap API key, returning mock data", "WARN")
            return {
                "success": True,
                "location": location,
                "temperature": 22,
                "unit": unit,
                "conditions": "Partly cloudy",
                "humidity": 65,
                "wind_speed": 10,
                "mock": True
            }
        
        # –î–µ–ª–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ OpenWeatherMap
        async with httpx.AsyncClient() as client:
            url = f"https://api.openweathermap.org/data/2.5/weather"
            params = {
                "q": location,
                "appid": api_key,
                "units": "metric" if unit == "celsius" else "imperial"
            }
            
            response = await client.get(url, params=params, timeout=10.0)
            response.raise_for_status()
            
            data = response.json()
            
            result = {
                "success": True,
                "location": data["name"],
                "temperature": round(data["main"]["temp"]),
                "unit": unit,
                "conditions": data["weather"][0]["description"],
                "humidity": data["main"]["humidity"],
                "wind_speed": round(data["wind"]["speed"]),
                "mock": False
            }
            
            log_to_render(f"[FUNCTION] Weather data: {result}")
            return result
            
    except Exception as e:
        log_to_render(f"[FUNCTION] get_current_weather error: {str(e)}", "ERROR")
        return {
            "success": False,
            "error": str(e)
        }

async def search_web(query: str, num_results: int = 3) -> Dict[str, Any]:
    """
    v2.10: Async web search function
    –ò—â–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ (–∏—Å–ø–æ–ª—å–∑—É—è DuckDuckGo –∏–ª–∏ –¥—Ä—É–≥–æ–π API)
    """
    log_to_render(f"[FUNCTION] search_web called with query: {query}")
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º DuckDuckGo HTML search (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á–∞)
        async with httpx.AsyncClient() as client:
            url = "https://html.duckduckgo.com/html/"
            data = {"q": query}
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
            
            response = await client.post(url, data=data, headers=headers, timeout=10.0)
            response.raise_for_status()
            
            # –ü–∞—Ä—Å–∏–º HTML —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            soup = BeautifulSoup(response.text, 'html.parser')
            results = []
            
            for result_div in soup.find_all('div', class_='result')[:num_results]:
                title_tag = result_div.find('a', class_='result__a')
                snippet_tag = result_div.find('a', class_='result__snippet')
                
                if title_tag and snippet_tag:
                    results.append({
                        "title": title_tag.get_text(strip=True),
                        "url": title_tag.get('href', ''),
                        "snippet": snippet_tag.get_text(strip=True)
                    })
            
            log_to_render(f"[FUNCTION] Found {len(results)} search results")
            
            return {
                "success": True,
                "query": query,
                "results": results,
                "count": len(results)
            }
            
    except Exception as e:
        log_to_render(f"[FUNCTION] search_web error: {str(e)}", "ERROR")
        return {
            "success": False,
            "error": str(e),
            "query": query
        }

# ==================== END FUNCTION IMPLEMENTATIONS ====================

async def handle_realtime_connection(
    websocket: WebSocket,
    assistant_id: str,
    db: SessionLocal
):
    """
    v2.11: –û–±—Ä–∞–±–æ—Ç—á–∏–∫ WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (OpenAI VAD Only - Simplified)
    
    –£–ü–†–û–©–ï–ù–ò–Ø v2.11:
    - –£–±—Ä–∞–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ input_audio_buffer.commit –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
    - –¢–æ–ª—å–∫–æ –ø–µ—Ä–µ—Å—ã–ª–∫–∞ audio chunks
    - OpenAI –¥–µ–ª–∞–µ—Ç VAD –∏ auto commit
    """
    
    log_to_render(f"[v2.11 OpenAI VAD] New WebSocket connection for assistant: {assistant_id}")
    
    # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è –∫–ª–∞—Å—Å–∞: AssistantConfig
    assistant = db.query(AssistantConfig).filter(AssistantConfig.id == assistant_id).first()
    
    if not assistant:
        log_to_render(f"Assistant not found: {assistant_id}", "ERROR")
        await websocket.close(code=4004, reason="Assistant not found")
        return
    
    log_to_render(f"[v2.11] Assistant found: {assistant.name}")
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞ OpenAI Realtime API
    openai_client = RealtimeClient(
        assistant_id=assistant_id,
        system_prompt=assistant.system_prompt,
        voice=assistant.voice or "alloy",
        temperature=assistant.temperature or 0.8
    )
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –∫–ª–∏–µ–Ω—Ç–µ
    log_to_render("[v2.11] Registering async functions...")
    
    # v2.10: –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º async —Ñ—É–Ω–∫—Ü–∏–∏
    openai_client.register_function("query_llm", query_llm, {
        "type": "function",
        "name": "query_llm",
        "description": "–î–µ–ª–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "–í–æ–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏"
                },
                "context": {
                    "type": "string",
                    "description": "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"
                }
            },
            "required": ["query"]
        }
    })
    
    openai_client.register_function("get_current_weather", get_current_weather, {
        "type": "function",
        "name": "get_current_weather",
        "description": "–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â—É—é –ø–æ–≥–æ–¥—É –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –ª–æ–∫–∞—Ü–∏–∏",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "–ì–æ—Ä–æ–¥ –∏–ª–∏ –ª–æ–∫–∞—Ü–∏—è, –Ω–∞–ø—Ä–∏–º–µ—Ä '–ú–æ—Å–∫–≤–∞' –∏–ª–∏ 'London'"
                },
                "unit": {
                    "type": "string",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "–ï–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã"
                }
            },
            "required": ["location"]
        }
    })
    
    openai_client.register_function("search_web", search_web, {
        "type": "function",
        "name": "search_web",
        "description": "–ò—â–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"
                },
                "num_results": {
                    "type": "integer",
                    "description": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3)",
                    "default": 3
                }
            },
            "required": ["query"]
        }
    })
    
    log_to_render("[v2.11] Functions registered successfully")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –≤ –∞–∫—Ç–∏–≤–Ω—ã—Ö
    connection_id = f"{assistant_id}_{id(websocket)}"
    active_connections[connection_id] = openai_client
    
    log_to_render(f"[v2.11] Active connections: {len(active_connections)}")
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ OpenAI
    await openai_client.connect()
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç—É
    await websocket.send_json({
        "type": "connection_status",
        "status": "connected",
        "message": "Connected to OpenAI Realtime API (v2.11 - OpenAI VAD Only)",
        "assistant_id": assistant_id
    })
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–±—ã—Ç–∏–π –æ—Ç OpenAI
    async def handle_openai_events():
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏–π –æ—Ç OpenAI –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –∫–ª–∏–µ–Ω—Ç—É"""
        try:
            while openai_client.is_connected:
                event = await openai_client.receive_event()
                
                if event:
                    event_type = event.get("type", "")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
                    if event_type not in [
                        "response.audio_transcript.delta",
                        "input_audio_buffer.speech_started",
                        "input_audio_buffer.speech_stopped"
                    ]:
                        log_to_render(f"[v2.11 OpenAI‚ÜíClient] {event_type}")
                    
                    # –ü–µ—Ä–µ—Å—ã–ª–∞–µ–º —Å–æ–±—ã—Ç–∏–µ –∫–ª–∏–µ–Ω—Ç—É
                    try:
                        await websocket.send_json(event)
                    except Exception as e:
                        log_to_render(f"[v2.11] Error sending event to client: {e}", "ERROR")
                        break
                
                await asyncio.sleep(0.01)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                
        except Exception as e:
            log_to_render(f"[v2.11] Error in OpenAI event handler: {e}", "ERROR")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏–π –æ—Ç OpenAI
    openai_task = asyncio.create_task(handle_openai_events())
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
    try:
        while True:
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
            try:
                message = await websocket.receive()
            except WebSocketDisconnect:
                log_to_render("[v2.11] Client disconnected")
                break
            except Exception as e:
                log_to_render(f"[v2.11] Error receiving message: {e}", "ERROR")
                break
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (JSON)
            if "text" in message:
                try:
                    data = json.loads(message["text"])
                    msg_type = data.get("type", "")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ —Ç–∏–ø—ã —Å–æ–æ–±—â–µ–Ω–∏–π
                    if msg_type not in ["input_audio_buffer.append", "ping"]:
                        log_to_render(f"[v2.11 Client‚ÜíOpenAI] {msg_type}")
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ ping/pong
                    if msg_type == "ping":
                        await websocket.send_text("pong")
                        continue
                    
                    # üî• v2.11: –£–ë–†–ê–ù–ê –æ–±—Ä–∞–±–æ—Ç–∫–∞ commit –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞!
                    # OpenAI –¥–µ–ª–∞–µ—Ç auto commit —á–µ—Ä–µ–∑ server VAD
                    if msg_type == "input_audio_buffer.commit":
                        log_to_render("[v2.11 VAD] ‚ö†Ô∏è Client sent commit - ignoring (OpenAI handles auto commit)", "WARN")
                        # –ù–µ –ø–µ—Ä–µ—Å—ã–ª–∞–µ–º –Ω–∞ OpenAI - OpenAI —Å–∞–º –¥–µ–ª–∞–µ—Ç commit!
                        continue
                    
                    # üî• v2.11: –£–ë–†–ê–ù–ê –æ–±—Ä–∞–±–æ—Ç–∫–∞ clear –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
                    # OpenAI —É–ø—Ä–∞–≤–ª—è–µ—Ç –±—É—Ñ–µ—Ä–æ–º —á–µ—Ä–µ–∑ server VAD
                    if msg_type == "input_audio_buffer.clear":
                        log_to_render("[v2.11 VAD] ‚ö†Ô∏è Client sent clear - ignoring (OpenAI manages buffer)", "WARN")
                        # –ù–µ –ø–µ—Ä–µ—Å—ã–ª–∞–µ–º - OpenAI —Å–∞–º —É–ø—Ä–∞–≤–ª—è–µ—Ç
                        continue
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ audio chunks - –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Å—ã–ª–∞–µ–º –Ω–∞ OpenAI
                    if msg_type == "input_audio_buffer.append":
                        if "audio" in data:
                            try:
                                # üî• v2.11: –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø–µ—Ä–µ—Å—ã–ª–∫–∞ - —Ç–æ–ª—å–∫–æ forward chunk
                                audio_base64 = data["audio"]
                                await openai_client.send_audio(audio_base64)
                            except Exception as e:
                                log_to_render(f"[v2.11] Error processing audio: {e}", "ERROR")
                        continue
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ screen capture
                    if msg_type == "screen.capture" or msg_type == "screen.context":
                        if "image" in data:
                            try:
                                log_to_render("[v2.11 SCREEN] Processing screen capture...")
                                
                                image_base64 = data["image"]
                                
                                # –£–¥–∞–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å data:image –µ—Å–ª–∏ –µ—Å—Ç—å
                                if "," in image_base64:
                                    image_base64 = image_base64.split(",")[1]
                                
                                # –§–æ—Ä–º–∏—Ä—É–µ–º prompt
                                if msg_type == "screen.context":
                                    # –¢–∏—Ö–∏–π —Ä–µ–∂–∏–º - –±–µ–∑ prompt, —Ç–æ–ª—å–∫–æ context
                                    prompt = None
                                    log_to_render("[v2.11 SCREEN] Silent context update (no prompt)")
                                else:
                                    # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º - —Å prompt
                                    prompt = data.get("prompt", "–û–ø–∏—à–∏ —á—Ç–æ —Ç—ã –≤–∏–¥–∏—à—å –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —ç–∫—Ä–∞–Ω–∞")
                                    log_to_render(f"[v2.11 SCREEN] With prompt: {prompt[:50]}...")
                                
                                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ OpenAI client
                                await openai_client.send_image(image_base64, prompt)
                                
                                log_to_render("[v2.11 SCREEN] Screen capture sent to OpenAI")
                                
                            except Exception as e:
                                log_to_render(f"[v2.11 SCREEN] Error processing screen: {e}", "ERROR")
                        continue
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–º–µ–Ω—ã –æ—Ç–≤–µ—Ç–∞ (–¥–ª—è –ø–µ—Ä–µ–±–∏–≤–∞–Ω–∏—è)
                    if msg_type == "response.cancel":
                        log_to_render("[v2.11 INTERRUPTION] Cancelling response...")
                        await openai_client.cancel_response()
                        continue
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ
                    if msg_type == "audio_playback.stopped":
                        log_to_render("[v2.11 INTERRUPTION] Audio playback stopped by client")
                        # –ü—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º, OpenAI —É–∂–µ –∑–Ω–∞–µ—Ç —á–µ—Ä–µ–∑ VAD
                        continue
                    
                    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–µ—Ä–µ—Å—ã–ª–∞–µ–º –Ω–∞ OpenAI –∫–∞–∫ –µ—Å—Ç—å
                    await openai_client.send_event(data)
                    
                except json.JSONDecodeError as e:
                    log_to_render(f"[v2.11] JSON decode error: {e}", "ERROR")
                except Exception as e:
                    log_to_render(f"[v2.11] Error processing message: {e}", "ERROR")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –∫–ª–∏–µ–Ω—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç)
            elif "bytes" in message:
                log_to_render("[v2.11] Received binary data (unexpected)", "WARN")
    
    except Exception as e:
        log_to_render(f"[v2.11] Error in main loop: {e}", "ERROR")
    
    finally:
        # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        log_to_render("[v2.11] Cleaning up connection...")
        
        # –û—Ç–º–µ–Ω—è–µ–º –∑–∞–¥–∞—á—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–±—ã—Ç–∏–π –æ—Ç OpenAI
        if not openai_task.done():
            openai_task.cancel()
            try:
                await openai_task
            except asyncio.CancelledError:
                pass
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å OpenAI
        await openai_client.disconnect()
        
        # –£–¥–∞–ª—è–µ–º –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        if connection_id in active_connections:
            del active_connections[connection_id]
        
        log_to_render(f"[v2.11] Connection closed. Active connections: {len(active_connections)}")
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º WebSocket –µ—Å–ª–∏ –µ—â–µ –æ—Ç–∫—Ä—ã—Ç
        try:
            await websocket.close()
        except Exception:
            pass

# ‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
async def handle_websocket_connection_new(websocket: WebSocket, assistant_id: str, db: SessionLocal):
    """Wrapper –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º"""
    await handle_realtime_connection(websocket, assistant_id, db)

async def get_active_connections_count() -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
    return len(active_connections)

async def disconnect_all():
    """–û—Ç–∫–ª—é—á–∞–µ—Ç –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
    log_to_render(f"[v2.11] Disconnecting all {len(active_connections)} connections...")
    
    for client in active_connections.values():
        try:
            await client.disconnect()
        except Exception as e:
            log_to_render(f"[v2.11] Error disconnecting client: {e}", "ERROR")
    
    active_connections.clear()
    log_to_render("[v2.11] All connections disconnected")
